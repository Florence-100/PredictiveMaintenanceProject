{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f810c9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "import random\n",
    "from solution import solution\n",
    "import time\n",
    "import scipy\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dc1c112",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f953de6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 4)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 15        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 8         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 4         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 9         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4)                 16        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55\n",
      "Trainable params: 55\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 15:54:17.075677: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-10 15:54:20.151366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14260 MB memory:  -> device: 0, name: Tesla V100-DGXS-16GB, pci bus id: 0000:07:00.0, compute capability: 7.0\n",
      "2022-03-10 15:54:20.152996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14592 MB memory:  -> device: 1, name: Tesla V100-DGXS-16GB, pci bus id: 0000:08:00.0, compute capability: 7.0\n",
      "2022-03-10 15:54:20.154578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 14592 MB memory:  -> device: 2, name: Tesla V100-DGXS-16GB, pci bus id: 0000:0e:00.0, compute capability: 7.0\n",
      "2022-03-10 15:54:20.155906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 8521 MB memory:  -> device: 3, name: Tesla V100-DGXS-16GB, pci bus id: 0000:0f:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "#load autoencoder model \n",
    "#input Layer\n",
    "input_layer = tf.keras.layers.Input(shape=(4, ))\n",
    "#Encoder\n",
    "encoder = tf.keras.layers.Dense(3, activation=\"tanh\")(input_layer)\n",
    "encoder = tf.keras.layers.Dense(2, activation='relu')(encoder)\n",
    "encoder = tf.keras.layers.Dense(1, activation=\"relu\")(encoder)\n",
    "# Decoder\n",
    "decoder = tf.keras.layers.Dense(2, activation='relu')(encoder)\n",
    "decoder = tf.keras.layers.Dense(3, activation='relu')(decoder)\n",
    "decoder = tf.keras.layers.Dense(4, activation='tanh')(decoder)\n",
    "#Autoencoder\n",
    "anomalyDetector = tf.keras.Model(inputs=input_layer, outputs=decoder)\n",
    "anomalyDetector.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f6250fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalyDetector.load_weights('AE_tuneActivation_code_relu.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bbdf620",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"GMM_values.csv\", header=0)\n",
    "\n",
    "#get failure times \n",
    "failurePoints = []\n",
    "for index, row in dataset.iterrows():\n",
    "    current_state = row['State']\n",
    "    if current_state > 3:\n",
    "        failurePoints.append(row['Timestep'])\n",
    "        \n",
    "def getRUL(current, failurelst):\n",
    "    nextFailure = None\n",
    "    for f in failurelst:\n",
    "        if f - current >= 0: \n",
    "            nextFailure = f\n",
    "            break \n",
    "    if nextFailure != None:\n",
    "        diff = nextFailure - current \n",
    "        return diff\n",
    "    else: \n",
    "        return None\n",
    "    \n",
    "#investigate general trend of RUL values \n",
    "total_rul = []\n",
    "timeX = dataset['Timestep'].tolist()\n",
    "for instance in timeX:\n",
    "    current_rul = getRUL(instance, failurePoints)\n",
    "    total_rul.append(current_rul)\n",
    "    \n",
    "#create a new dataframe with RUL \n",
    "all_df = dataset.copy(deep=True)\n",
    "all_df['RUL'] = total_rul\n",
    "\n",
    "#get starting points \n",
    "startingPoints = []\n",
    "for index, row in dataset.iterrows():\n",
    "    current_state = row['State']\n",
    "    if current_state > 3:\n",
    "        timePoint = row['Timestep'] + 1\n",
    "        startingPoints.append(timePoint)\n",
    "\n",
    "def getTimeFromStart(current, startList):\n",
    "    currentEpisodeStartIndex = -1 #initialise negative value first\n",
    "    for s in range(len(startList)):\n",
    "        start = startList[s]\n",
    "        if start - current > 0: \n",
    "            break \n",
    "        currentEpisodeStartIndex = s\n",
    "    if currentEpisodeStartIndex >= 0:\n",
    "        startPointTime = startList[currentEpisodeStartIndex]\n",
    "        diff = current - startPointTime\n",
    "        return int(diff)\n",
    "    else: \n",
    "        return current\n",
    "\n",
    "#get data on time elapsed from start of episode \n",
    "total_time_from_start = []\n",
    "for timePoint in timeX:\n",
    "    current_time_from_start = getTimeFromStart(timePoint, startingPoints)\n",
    "    total_time_from_start.append(current_time_from_start)\n",
    "    \n",
    "all_df['Time_elapsed'] = total_time_from_start\n",
    "\n",
    "anomalyData = []\n",
    "\n",
    "for index, row in all_df.iterrows():\n",
    "    sensorReadings = np.array([row['Volt'], row['Rotate'], row['Pressure'], row['Vibration']])\n",
    "    sensorReadings = np.reshape(sensorReadings, (1,4))\n",
    "    predictions = anomalyDetector.predict(sensorReadings)\n",
    "    anomalyScore = (np.mean(np.power(sensorReadings - predictions, 2), axis=1))**0.5\n",
    "    \n",
    "    if anomalyScore < 0.0838:\n",
    "        isAnomaly = 0\n",
    "    else:\n",
    "        isAnomaly = 1\n",
    "        \n",
    "    anomalyData.append(isAnomaly)\n",
    "    \n",
    "all_df['Anomalous'] = anomalyData\n",
    "\n",
    "#drop na columns \n",
    "all_df = all_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3c1afec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data processing\n",
    "#split data into episodes\n",
    "data_split = []\n",
    "chunkBySize = []\n",
    "for index, row in all_df.iterrows():\n",
    "    currentRUL = row['RUL']\n",
    "    arr = [row['Timestep'], row['Volt'], row['Rotate'], row['Pressure'], row['Vibration'], row['Time_elapsed'], row['Anomalous'], row['RUL'], row['State']]\n",
    "    if currentRUL < 1:  \n",
    "        chunkBySize.append(arr)\n",
    "        if (chunkBySize):\n",
    "            data_split.append(chunkBySize)\n",
    "        chunkBySize = []\n",
    "    else:\n",
    "        chunkBySize.append(arr)\n",
    "        \n",
    "num_episodes = len(data_split)\n",
    "num_train = int(0.75*num_episodes)\n",
    "num_val = int(0.125*num_episodes)\n",
    "\n",
    "#split into training, validation and test sets\n",
    "train_data = data_split[:num_train]\n",
    "val_data = data_split[num_train:num_train+num_val]\n",
    "test_data = data_split[num_train+num_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf761968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataIntoChunks3DWithAnomalyTimeInfo(data, chunk_size):\n",
    "    X_split = []\n",
    "    y_split = []\n",
    "    time_split = []\n",
    "    for episode in data:\n",
    "        for order in range(0, len(episode)):\n",
    "            diff = len(episode) - order\n",
    "            if diff > chunk_size:\n",
    "                episode_chunk = []\n",
    "                for i in range(0, chunk_size):\n",
    "                    reading = episode[order+i]\n",
    "                    episode_chunk.append(reading[1:7])\n",
    "                X_split.append(episode_chunk)\n",
    "                y_split.append(episode[order+chunk_size][7])\n",
    "                time_split.append(int(episode[order+chunk_size][0]))\n",
    "    return (X_split, y_split, time_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e681ccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set random seed \n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fae157a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findSscore(actualRULlist, predictedRULlist):\n",
    "    Sscore = 0\n",
    "    for order in range(len(actualRULlist)):\n",
    "        actualRUL = actualRULlist[order]\n",
    "        predictedRUL = predictedRULlist[order]\n",
    "        diff = abs(actualRUL - predictedRUL)\n",
    "        if predictedRUL < actualRUL: #underestimate\n",
    "            multiplier = 1/13\n",
    "        else: #overestimate\n",
    "            multiplier = 1/10\n",
    "        factor = multiplier*diff\n",
    "        score = math.exp(factor)\n",
    "        Sscore += score\n",
    "    return Sscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d9df111",
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX_4step_TAD, trainY_4step_TAD, trainTime_4step_TAD) = splitDataIntoChunks3DWithAnomalyTimeInfo(train_data, 4)\n",
    "(valX_4step_TAD, valY_4step_TAD, valTime_4step_TAD) = splitDataIntoChunks3DWithAnomalyTimeInfo(val_data, 4)\n",
    "(testX_4step_TAD, testY_4step_TAD, testTime_4step_TAD) = splitDataIntoChunks3DWithAnomalyTimeInfo(test_data, 4)\n",
    "\n",
    "trainX_4step_TAD_arr = np.array(trainX_4step_TAD)\n",
    "trainY_4step_TAD_arr = np.array(trainY_4step_TAD)\n",
    "trainY_4step_TAD_arr = trainY_4step_TAD_arr.reshape(-1, 1)\n",
    "\n",
    "valX_4step_TAD_arr = np.array(valX_4step_TAD)\n",
    "valY_4step_TAD_arr = np.array(valY_4step_TAD)\n",
    "valY_4step_TAD_arr = valY_4step_TAD_arr.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1faa7695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findFitnessScore(lst):\n",
    "    \n",
    "    #get parameters\n",
    "    numFilters1 = int(lst[0])\n",
    "    numFilters2 = int(lst[1])\n",
    "    numFilters3 = int(lst[2])\n",
    "    dr1 = lst[3]\n",
    "    dr2 = lst[4]\n",
    "    numNeurons1 = int(lst[5])\n",
    "    lr_factor = int(lst[6])\n",
    "    lr = 10**(-lr_factor)\n",
    "    beta1 = lst[7]\n",
    "    beta2 = lst[8]\n",
    "    epsilon = lst[9]\n",
    "    global global_counter\n",
    "    \n",
    "    #build model architecture\n",
    "    #configure architecture \n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv1D(filters=numFilters1, kernel_size=3, activation='relu', input_shape=(4, 6), padding=\"same\"))\n",
    "    model.add(layers.Conv1D(filters=numFilters2, kernel_size=2, activation='relu', padding=\"same\"))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2, padding='same'))\n",
    "    model.add(layers.Dropout(dr1))\n",
    "    model.add(layers.Conv1D(filters=numFilters3, kernel_size=1, activation='relu'))\n",
    "    model.add(layers.Dropout(dr2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(numNeurons1, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='relu'))\n",
    "    \n",
    "    adam = tf.keras.optimizers.Adam(learning_rate=lr, beta_1=beta1, beta_2=beta2, epsilon=epsilon)\n",
    "    model.compile(loss='mean_squared_error', optimizer=adam, metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    \n",
    "    #save best model\n",
    "    fileName = \"CNN_tuneWithGWO_withTime.h5\"\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=fileName,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_mean_squared_error',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "    \n",
    "    model.fit(trainX_4step_TAD_arr, trainY_4step_TAD_arr, epochs=500, batch_size=32, validation_data=(valX_4step_TAD_arr, valY_4step_TAD_arr), shuffle=False, verbose=0, callbacks=[model_checkpoint_callback])\n",
    "    \n",
    "    bestModel = tf.keras.models.load_model(\"CNN_tuneWithGWO_withTime.h5\")\n",
    "    valPredict = bestModel.predict(valX_4step_TAD_arr)\n",
    "    valScore = math.sqrt(mean_squared_error(valY_4step_TAD_arr, valPredict))\n",
    "    valR2Score = r2_score(valY_4step_TAD_arr, valPredict)\n",
    "    valsScore = findSscore(valY_4step_TAD_arr, valPredict)\n",
    "    params_lst = [numFilters1, numFilters2, numFilters3, dr1, dr2, numNeurons1, lr, beta1, beta2, epsilon]\n",
    "    print(f'Validation Score: {valScore} RMSE {valR2Score} R2 Score {valsScore} S score at round {global_counter} for parameters {params_lst}')\n",
    "    \n",
    "    global_counter += 1\n",
    "    \n",
    "    return (valsScore, params_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d82f807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GWO(modelTraining, lowerBoundValuesList, upperBoundValuesList, numParams, numWolves, Max_iter):\n",
    "\n",
    "    # Max_iter=1000\n",
    "    # upperBoundValuesList= list of upper bound of parameter values \n",
    "    # lowerBoundValuesList = list of lower bound of parameter values\n",
    "    # numParams = number of hyperparameters to tune \n",
    "    # numWolves = 5\n",
    "    # modelTraining = function to train machine learning model \n",
    "    \n",
    "    #show best params of alpha wolf\n",
    "    bestParams = []\n",
    "\n",
    "    # initialize alpha, beta_pos\n",
    "    Alpha_pos = np.zeros(numParams)\n",
    "    Alpha_score = float(\"inf\")\n",
    "\n",
    "    Beta_pos = np.zeros(numParams)\n",
    "    Beta_score = float(\"inf\")\n",
    "\n",
    "    # Initialize the positions of search agents\n",
    "    Positions = np.zeros((numWolves, numParams))\n",
    "    for i in range(numParams):\n",
    "        Positions[:, i] = (\n",
    "            np.random.uniform(0, 1, numWolves) * (upperBoundValuesList[i] - lowerBoundValuesList[i]) + lowerBoundValuesList[i]\n",
    "        )\n",
    "\n",
    "    Convergence_curve = np.zeros(Max_iter)\n",
    "    s = solution()\n",
    "\n",
    "    timerStart = time.time()\n",
    "    s.startTime = time.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    \n",
    "    #initialise parameters \n",
    "    wa = 0.5\n",
    "    \n",
    "    # Main loop\n",
    "    for l in range(0, Max_iter):\n",
    "        for i in range(0, numWolves):\n",
    "\n",
    "            # Return back the wolves that go beyond the boundaries of the search space\n",
    "            for j in range(numParams):\n",
    "                Positions[i, j] = np.clip(Positions[i, j], lowerBoundValuesList[j], upperBoundValuesList[j]) #numpy.clip limits values in an array\n",
    "\n",
    "            # Calculate objective function for each wolf\n",
    "            (fitness, params) = modelTraining(Positions[i, :])\n",
    "\n",
    "            # Update Alpha, Beta, and Delta\n",
    "            if fitness < Alpha_score: #this is new alpha wolf \n",
    "                Beta_score = Alpha_score  # Update beta\n",
    "                Beta_pos = Alpha_pos.copy()\n",
    "                Alpha_score = fitness\n",
    "                # Update alpha\n",
    "                Alpha_pos = Positions[i, :].copy()\n",
    "                bestParams = params\n",
    "\n",
    "            if fitness > Alpha_score and fitness < Beta_score: #this is beta wolf \n",
    "                Beta_score = fitness  # Update beta\n",
    "                Beta_pos = Positions[i, :].copy()\n",
    "\n",
    "        theta = l/Max_iter\n",
    "        fraction = ((math.tanh(theta))**2 + (theta*math.sin(math.pi*theta))**5)/(math.tanh(1))**2\n",
    "        factor = fraction * (math.pi/2)\n",
    "        a = 2 * (math.cos(factor))**2 #exploration rate \n",
    "        \n",
    "        #chaotic dominance \n",
    "        wa = 2.3 * (wa**2) * math.sin(math.pi*wa)\n",
    "        wbd = 0.5 * (1-wa)\n",
    "            \n",
    "        if (l < 0.8*Max_iter):\n",
    "\n",
    "            # Update the Position of search agents including omegas\n",
    "            for i in range(0, numWolves):\n",
    "                for j in range(0, numParams):\n",
    "                    \n",
    "    \n",
    "                    r1 = random.random()\n",
    "                    r2 = random.random()\n",
    "                    A1 = (2*r1 - 1)*a\n",
    "                    C1 = 2 * r2\n",
    "    \n",
    "                    D_alpha = abs(C1 * Alpha_pos[j] - Positions[i, j])\n",
    "                    # Equation (3.5)-part 1\n",
    "                    X1 = Alpha_pos[j] - A1 * D_alpha\n",
    "                    # Equation (3.6)-part 1\n",
    "    \n",
    "                    r1 = random.random()\n",
    "                    r2 = random.random()\n",
    "    \n",
    "                    A2 = (2*r1 - 1)*a\n",
    "                    # Equation (3.3)\n",
    "                    C2 = 2 * r2\n",
    "                    # Equation (3.4)\n",
    "    \n",
    "                    D_beta = abs(C2 * Beta_pos[j] - Positions[i, j])\n",
    "                    # Equation (3.5)-part 2\n",
    "                    X2 = Beta_pos[j] - A2 * D_beta\n",
    "                    # Equation (3.6)-part 2\n",
    "    \n",
    "                    Positions[i, j] = wa*X1 + wbd*X2 # update position of each wolf\n",
    "                    \n",
    "        else: \n",
    "            \n",
    "            # Update the Position of search agents including omegas\n",
    "            for i in range(0, numWolves):\n",
    "                for j in range(0, numParams):\n",
    "                    \n",
    "                    amplitude = 1 - (0.05*(l - 0.8*Max_iter))\n",
    "                    rand = random.uniform(-1, 1) #generate random float between -1 and 1 \n",
    "                    step_size = amplitude * (math.exp(3*(rand**2)*0.5)) * math.cos(math.pi*rand) * math.sin(math.pi*rand)\n",
    "                    Positions[i, j] = Alpha_pos[j] - step_size*abs(Alpha_pos[j] - Positions[i, j])\n",
    "\n",
    "        Convergence_curve[l] = Alpha_score\n",
    "\n",
    "        if l % 1 == 0:\n",
    "            print(\n",
    "                \"At iteration \" + str(l) + \" the best S score is \" + str(Alpha_score)\n",
    "            )\n",
    "            print(bestParams)\n",
    "\n",
    "    timerEnd = time.time()\n",
    "    s.endTime = time.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    s.executionTime = timerEnd - timerStart\n",
    "    s.convergence = Convergence_curve\n",
    "    s.bestIndividual = bestParams\n",
    "    s.best = Alpha_score\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d908e5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramsUpperBoundList = [4096, 2048, 1024, 0.95, 0.95, 4096, 10, 0.999, 0.999, 5]\n",
    "paramsLowerBoundList = [1, 1, 1, 0, 0, 1, 0, 0, 0, 0.1]\n",
    "numParams = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1af3ff93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 16:02:07.298944: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 0 for parameters [3777, 1552, 210, 0.42301603366274126, 0.7497304202459437, 1891, 1, 0.1658854228552624, 0.5475392051817545, 0.20677112902970285]\n",
      "Validation Score: 5.392119486652663 RMSE -1.5380999746566428 R2 Score 910.0392083011267 S score at round 1 for parameters [3143, 1879, 608, 0.1428624307037438, 0.4005835464993584, 221, 1e-08, 0.482887078176915, 0.800398377910834, 1.1712539895604308]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 2 for parameters [2610, 989, 456, 0.38902180092134564, 0.06511783582643994, 2822, 1e-09, 0.4683712974717498, 0.8573046541275189, 3.8740335304489317]\n",
      "Validation Score: 5.3894003811653395 RMSE -1.5355408245869704 R2 Score 909.8728915910644 S score at round 3 for parameters [4091, 1522, 850, 0.38104755459565676, 0.21367743704723174, 1692, 1e-08, 0.5784029844497831, 0.6720513442489034, 2.108403558646927]\n",
      "Validation Score: 2.9705169903161077 RMSE 0.22971083071746567 R2 Score 798.3352056190363 S score at round 4 for parameters [3329, 1224, 891, 0.3809811374173541, 0.7152046478782781, 2112, 1e-05, 0.3237145240159802, 0.7417859025999379, 0.11655504484972037]\n",
      "At iteration 0 the best S score is 798.3352056190363\n",
      "[3329, 1224, 891, 0.3809811374173541, 0.7152046478782781, 2112, 1e-05, 0.3237145240159802, 0.7417859025999379, 0.11655504484972037]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 5 for parameters [1746, 1476, 1024, 0.19703772774747674, 0.0, 628, 0.1, 0.4343801905108243, 0.5319817067485682, 0.1]\n",
      "Validation Score: 2.9842473433068823 RMSE 0.22257349720245856 R2 Score 793.0988894778874 S score at round 6 for parameters [2657, 403, 486, 0.5631301496481076, 0.754758722191096, 3035, 1e-06, 0.0901628158896903, 0.665273004704455, 0.2671262620968734]\n",
      "Validation Score: 3.0214812452676374 RMSE 0.20305286123583066 R2 Score 804.0344252561785 S score at round 7 for parameters [2368, 1479, 775, 0.0, 0.6888743510100904, 1260, 1e-05, 0.4980246683872732, 0.06411647540979867, 3.2583640929438378]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 8 for parameters [4096, 1016, 1024, 0.22670429148385463, 0.40412734851366217, 2304, 1, 0.122924689568185, 0.703951140585151, 0.39171697069252026]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 9 for parameters [2046, 1320, 682, 0.49184110323995983, 0.42665421712620144, 1, 1e-05, 0.4707600101084819, 0.7856592158253912, 0.1]\n",
      "At iteration 1 the best S score is 793.0988894778874\n",
      "[2657, 403, 486, 0.5631301496481076, 0.754758722191096, 3035, 1e-06, 0.0901628158896903, 0.665273004704455, 0.2671262620968734]\n",
      "Validation Score: 3.2127301400782065 RMSE 0.09897216994679225 R2 Score 811.8663001375988 S score at round 10 for parameters [1461, 11, 1, 0.799660726657842, 0.6303097708539804, 615, 1e-05, 0.0, 0.6546879357761741, 0.1]\n",
      "Validation Score: 2.9264633980754455 RMSE 0.25238862028750575 R2 Score 792.1656971064226 S score at round 11 for parameters [2188, 778, 268, 0.8347525320346444, 0.11891975527751258, 2797, 1e-05, 0.15791248624583767, 0.7037046011048904, 0.31917678376199615]\n",
      "Validation Score: 5.4128203003991215 RMSE -1.5576253539408005 R2 Score 911.6017625848397 S score at round 12 for parameters [4096, 1641, 601, 0.4794870353959912, 0.6823720411485846, 2601, 1e-10, 0.0, 0.7491281362414975, 0.1]\n",
      "Validation Score: 3.1014128888371513 RMSE 0.16032952062384764 R2 Score 802.0691995858799 S score at round 13 for parameters [1, 1, 494, 0.6872957212446477, 0.46040847847408445, 4096, 0.001, 0.0, 0.676690825667047, 0.1]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 14 for parameters [4096, 1, 402, 0.95, 0.6156279957008357, 1, 1e-06, 0.0, 0.5702392566108181, 0.10885838565934021]\n",
      "At iteration 2 the best S score is 792.1656971064226\n",
      "[2188, 778, 268, 0.8347525320346444, 0.11891975527751258, 2797, 1e-05, 0.15791248624583767, 0.7037046011048904, 0.31917678376199615]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 15 for parameters [1624, 1, 331, 0.95, 0.48170385710921076, 2841, 1, 0.09474979221132994, 0.3715002207784556, 0.3143370774082505]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 16 for parameters [2266, 326, 403, 0.935030181625184, 0.06643090519923711, 1916, 0.01, 0.19420112478761678, 0.6633801939194847, 0.4221266957871105]\n",
      "Validation Score: 4.983634371059747 RMSE -1.1681137056004682 R2 Score 881.4929510124491 S score at round 17 for parameters [2101, 602, 1, 0.95, 0.7073111495476716, 1, 1e-07, 0.2446061768348644, 0.8708303304376313, 0.34500014732488504]\n",
      "Validation Score: 5.429192594155535 RMSE -1.5731209810814217 R2 Score 912.7721851451615 S score at round 18 for parameters [1541, 411, 198, 0.711259671943079, 0.25243345688451696, 4096, 1e-09, 0.3915162420549075, 0.47280855520166415, 0.3899976025418989]\n",
      "Validation Score: 3.040111363578642 RMSE 0.1931947873784523 R2 Score 806.09549333965 S score at round 19 for parameters [3494, 2048, 234, 0.5271789533407172, 0.0, 2411, 1e-06, 0.27637606533715225, 0.5935605718271553, 0.31764392019666293]\n",
      "At iteration 3 the best S score is 792.1656971064226\n",
      "[2188, 778, 268, 0.8347525320346444, 0.11891975527751258, 2797, 1e-05, 0.15791248624583767, 0.7037046011048904, 0.31917678376199615]\n",
      "Validation Score: 2.9414146869141886 RMSE 0.24473001964881713 R2 Score 790.7711792148285 S score at round 20 for parameters [1762, 644, 23, 0.6246587337369578, 0.0, 3325, 0.001, 0.10480766936081022, 0.33163653774797, 0.2164441055325189]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 21 for parameters [1727, 1010, 1, 0.3344643098703821, 0.3037344034642488, 1988, 1e-09, 0.10974182159100299, 0.555320526872422, 0.2780779932841126]\n",
      "Validation Score: 2.8430224714361847 RMSE 0.29441344807788183 R2 Score 785.5174018310078 S score at round 22 for parameters [3125, 459, 80, 0.5396159101366573, 0.0, 4096, 0.0001, 0.04579536114299372, 0.7899034852113153, 0.1]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 23 for parameters [667, 483, 232, 0.4911443862031629, 0.14584364737509745, 3177, 1e-09, 0.0, 0.41659656900297365, 0.20146798502708949]\n",
      "Validation Score: 2.892412263515844 RMSE 0.26968520563314224 R2 Score 787.9654963376298 S score at round 24 for parameters [1801, 705, 192, 0.0, 0.1055977664224379, 2538, 0.001, 0.15004461035892275, 0.4128636906621106, 0.1]\n",
      "At iteration 4 the best S score is 785.5174018310078\n",
      "[3125, 459, 80, 0.5396159101366573, 0.0, 4096, 0.0001, 0.04579536114299372, 0.7899034852113153, 0.1]\n",
      "Validation Score: 2.9218650796617496 RMSE 0.25473620086768145 R2 Score 791.4885840718251 S score at round 25 for parameters [1689, 383, 82, 0.15212313761629018, 0.07778542848827673, 2518, 0.001, 0.10872175574381496, 0.5993681439521212, 0.20173303486096483]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 26 for parameters [2464, 391, 81, 0.2767828117667619, 0.0, 3188, 1, 0.005246039547614427, 0.5316786092588933, 0.1]\n",
      "Validation Score: 2.9155195748333367 RMSE 0.2579697108126854 R2 Score 787.4866857624902 S score at round 27 for parameters [1564, 415, 93, 0.7135987872886691, 0.06751526911650484, 4096, 0.0001, 0.09526694715082168, 0.42258201040327725, 0.1]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 28 for parameters [934, 541, 164, 0.35672156591287074, 0.10266222010667442, 4096, 1, 0.08357163251140001, 0.24291548652961298, 0.19323487377531828]\n",
      "Validation Score: 2.9400352850685674 RMSE 0.24543823432118983 R2 Score 789.9084212662069 S score at round 29 for parameters [1274, 750, 50, 0.2331457214807477, 0.06335776538275259, 2956, 0.001, 0.07652544553907, 0.4360635038787923, 0.1]\n",
      "At iteration 5 the best S score is 785.5174018310078\n",
      "[3125, 459, 80, 0.5396159101366573, 0.0, 4096, 0.0001, 0.04579536114299372, 0.7899034852113153, 0.1]\n",
      "Validation Score: 2.872676037925865 RMSE 0.27961773308844207 R2 Score 790.6507078760043 S score at round 30 for parameters [868, 375, 48, 0.5248486093805375, 0.06644198074952537, 4096, 0.0001, 0.0, 0.5862215952643093, 0.1]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 31 for parameters [3272, 234, 73, 0.2301357679890702, 0.01037291461784914, 3339, 1, 0.007626525823822044, 0.5633729650366942, 0.1]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 32 for parameters [3379, 6, 85, 0.6289678442042028, 0.0, 39, 0.1, 0.021162482538822632, 0.6211740683821663, 0.1]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 33 for parameters [2480, 640, 45, 0.3827128280190746, 0.08659604509770424, 2507, 1, 0.0508750032823511, 0.5911960783257695, 0.11249244904168727]\n",
      "Validation Score: 2.9265308194071986 RMSE 0.2523541721987207 R2 Score 789.5318288175366 S score at round 34 for parameters [1920, 589, 37, 0.4693244391307676, 0.045747751694530187, 2060, 0.001, 0.03988614966419389, 0.0, 0.1]\n",
      "At iteration 6 the best S score is 785.5174018310078\n",
      "[3125, 459, 80, 0.5396159101366573, 0.0, 4096, 0.0001, 0.04579536114299372, 0.7899034852113153, 0.1]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 35 for parameters [1, 1, 77, 0.49938598342045615, 0.0, 2791, 0.0001, 0.03773905766789106, 0.999, 0.12712932279983624]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 36 for parameters [2704, 374, 74, 0.6868377847551036, 0.0, 1, 1e-05, 0.06605975359049868, 0.5816554599865341, 0.12430161020981921]\n",
      "Validation Score: 2.9355826471026774 RMSE 0.24772204785720353 R2 Score 790.4849863034901 S score at round 37 for parameters [4096, 193, 125, 0.6937948868313308, 0.0042813854684570895, 4096, 1e-05, 0.10544938250346624, 0.999, 0.1]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 38 for parameters [2470, 323, 16, 0.9281998321759407, 0.02229657012835858, 4042, 0.1, 0.0813837628135214, 0.6906826421275675, 0.20118224094160794]\n",
      "Validation Score: 3.3898481532681153 RMSE -0.0031137864087376066 R2 Score 819.8813234089255 S score at round 39 for parameters [4096, 425, 1, 0.5399337733172676, 0.0, 1, 1, 0.036817784257491055, 0.7550786137378909, 0.1]\n",
      "At iteration 7 the best S score is 785.5174018310078\n",
      "[3125, 459, 80, 0.5396159101366573, 0.0, 4096, 0.0001, 0.04579536114299372, 0.7899034852113153, 0.1]\n",
      "Validation Score: 4.441714201634312 RMSE -0.7222291336984403 R2 Score 865.0281870722321 S score at round 40 for parameters [1756, 506, 34, 0.8222321365063656, 0.027543392138000212, 4096, 1e-07, 0.0, 0.5087684443524508, 0.1]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 41 for parameters [808, 559, 68, 0.5469659102869479, 0.03493510382758367, 1499, 0.01, 0.05689780835740284, 0.26979414181477507, 0.1]\n",
      "Validation Score: 2.923311581331502 RMSE 0.2539981160180105 R2 Score 788.818270633815 S score at round 42 for parameters [3198, 471, 110, 0.7587421953886695, 0.044478711557838786, 3227, 0.0001, 0.13874667423298817, 0.5922722231593712, 0.15891094421283322]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 43 for parameters [773, 350, 99, 0.42883965481102093, 0.02314862215658914, 2969, 0.1, 0.0671744476661869, 0.8043104973317499, 0.12340260154401396]\n",
      "Validation Score: 4.4102413651960655 RMSE -0.6979090637307106 R2 Score 862.1090263911974 S score at round 44 for parameters [1120, 45, 78, 0.5768700160212237, 0.0, 4054, 1e-07, 0.006940756611330539, 0.2492067051525618, 0.10495767697885769]\n",
      "At iteration 8 the best S score is 785.5174018310078\n",
      "[3125, 459, 80, 0.5396159101366573, 0.0, 4096, 0.0001, 0.04579536114299372, 0.7899034852113153, 0.1]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 45 for parameters [3632, 73, 55, 0.6664550499563442, 0.03284943029694115, 3485, 0.01, 0.0, 0.588576420562593, 0.1]\n",
      "Validation Score: 2.949863984188113 RMSE 0.24038471863745203 R2 Score 797.740690253124 S score at round 46 for parameters [1956, 345, 98, 0.4258232960717275, 0.0, 878, 1e-05, 0.053368376645479616, 0.8418419504966749, 0.1]\n",
      "Validation Score: 2.9573507899989284 RMSE 0.23652399210763908 R2 Score 799.7205825436181 S score at round 47 for parameters [4069, 271, 83, 0.43044149119834796, 0.0, 2293, 1e-05, 0.09792053135567659, 0.9963910635238276, 0.10638572585180626]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 48 for parameters [2194, 117, 90, 0.4731205407753999, 0.045191061891965034, 4096, 0.1, 0.07120885387408568, 0.0, 0.1]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 49 for parameters [2606, 231, 126, 0.0, 0.021331932828140245, 2565, 1, 0.07798600546689063, 0.46650567256543396, 0.1]\n",
      "At iteration 9 the best S score is 785.5174018310078\n",
      "[3125, 459, 80, 0.5396159101366573, 0.0, 4096, 0.0001, 0.04579536114299372, 0.7899034852113153, 0.1]\n",
      "Validation Score: 2.901714718506018 RMSE 0.26498003588363106 R2 Score 796.578321573937 S score at round 50 for parameters [2681, 263, 90, 0.42568105951157903, 0.02041691036259602, 4096, 0.0001, 0.0, 0.999, 0.1]\n",
      "Validation Score: 2.9022504691258595 RMSE 0.2647085937933247 R2 Score 788.4576817405515 S score at round 51 for parameters [4096, 71, 164, 0.8529604326177512, 0.005631246161857558, 922, 0.001, 0.09200975555772184, 0.9215385882237402, 0.148413624239483]\n",
      "Validation Score: 2.9635437644070817 RMSE 0.23332306103674938 R2 Score 801.061914504694 S score at round 52 for parameters [2705, 1128, 86, 0.529787674343393, 0.005134462757277869, 2970, 0.001, 0.10057833243881315, 0.7885113539603341, 0.1]\n",
      "Validation Score: 2.84534223301312 RMSE 0.29326153291822254 R2 Score 788.0667195316385 S score at round 53 for parameters [4096, 550, 99, 0.2666583212974103, 0.06213393305069525, 4096, 0.0001, 0.04293458617396153, 0.767134842949164, 0.1]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 54 for parameters [3846, 473, 22, 0.7581862191610306, 0.02485762268021412, 4035, 0.01, 0.08289091171688787, 0.695879787039025, 0.1]\n",
      "At iteration 10 the best S score is 785.5174018310078\n",
      "[3125, 459, 80, 0.5396159101366573, 0.0, 4096, 0.0001, 0.04579536114299372, 0.7899034852113153, 0.1]\n",
      "Validation Score: 2.939587786059252 RMSE 0.24566791860184822 R2 Score 797.5075235264306 S score at round 55 for parameters [3539, 714, 67, 0.2294678798240033, 0.01824509470100815, 4096, 0.001, 0.03198729837409986, 0.999, 0.1029316795727687]\n",
      "Validation Score: 2.8877623348295742 RMSE 0.2720314700784878 R2 Score 787.2623565038771 S score at round 56 for parameters [1432, 248, 74, 0.39755842632844474, 0.007055801763142302, 4096, 0.0001, 0.0, 0.04347699210170647, 0.15574455215029817]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 57 for parameters [3101, 1512, 119, 0.5662143451752016, 0.007453950652808924, 4096, 0.1, 0.0, 0.7103845054960137, 0.14000205515854028]\n",
      "Validation Score: 3.3724159036120467 RMSE 0.007176685048431497 R2 Score 796.8434264368761 S score at round 58 for parameters [3058, 401, 79, 0.95, 0.0, 4096, 1e-05, 0.07930533593732854, 0.8405523167765483, 0.16448558131743052]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 59 for parameters [2799, 305, 117, 0.5018816596992157, 0.005894314376783849, 1362, 1, 0.05256212366594884, 0.9913237261704987, 0.10924827125633495]\n",
      "At iteration 11 the best S score is 785.5174018310078\n",
      "[3125, 459, 80, 0.5396159101366573, 0.0, 4096, 0.0001, 0.04579536114299372, 0.7899034852113153, 0.1]\n",
      "Validation Score: 2.935770116469779 RMSE 0.2476259622812491 R2 Score 793.0558841321867 S score at round 60 for parameters [4067, 1014, 91, 0.5687088696534955, 0.0, 3786, 0.001, 0.028437090144543358, 0.44148871561453906, 0.1]\n",
      "Validation Score: 4.402652891986535 RMSE -0.6920710827681209 R2 Score 866.9402936495295 S score at round 61 for parameters [2632, 52, 56, 0.4183639923383998, 0.0, 4096, 1e-07, 0.025858969701923962, 0.0, 0.1]\n",
      "Validation Score: 2.9346411169980895 RMSE 0.2482045270367802 R2 Score 795.7134943435374 S score at round 62 for parameters [2693, 903, 76, 0.43296903164204226, 0.0, 3176, 0.001, 0.03641771526518273, 0.6736040549719595, 0.10775646428324301]\n",
      "Validation Score: 2.9568422036328665 RMSE 0.23678656501689366 R2 Score 793.0074604796329 S score at round 63 for parameters [2221, 538, 78, 0.1871809935808248, 0.001295286548057178, 2885, 0.001, 0.0716823211645141, 0.9031480822852566, 0.1]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 64 for parameters [2795, 989, 27, 0.5074614821873613, 0.0, 4096, 0.1, 0.0680414867523336, 0.43940415098148433, 0.1]\n",
      "At iteration 12 the best S score is 785.5174018310078\n",
      "[3125, 459, 80, 0.5396159101366573, 0.0, 4096, 0.0001, 0.04579536114299372, 0.7899034852113153, 0.1]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 65 for parameters [2949, 452, 136, 0.3689375302889815, 0.0002866421336121615, 2610, 1, 0.059715568915489944, 0.015350676972638254, 0.1]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 66 for parameters [4096, 415, 107, 0.6177188173462048, 0.0003305166360296338, 4096, 1, 0.013712344352434057, 0.019464236663547782, 0.1]\n",
      "Validation Score: 2.9590169830317388 RMSE 0.23566345384201504 R2 Score 794.348081749432 S score at round 67 for parameters [2972, 643, 75, 0.28472555089911183, 0.0004261618069366185, 4096, 0.001, 0.04651859482744058, 0.6930946778137563, 0.203607148337295]\n",
      "Validation Score: 3.2665309917887275 RMSE 0.06854200233432306 R2 Score 808.6777739685384 S score at round 68 for parameters [821, 1, 59, 0.3704274205934066, 0.0, 4096, 1e-06, 0.04144245669173172, 0.7051398755926843, 0.17328346804591765]\n",
      "Validation Score: 2.9100538114693553 RMSE 0.26074929103509226 R2 Score 798.2397996876011 S score at round 69 for parameters [3589, 568, 66, 0.3916443851485033, 0.0001922705332803064, 2681, 0.0001, 0.10159981431524466, 0.999, 0.1]\n",
      "At iteration 13 the best S score is 785.5174018310078\n",
      "[3125, 459, 80, 0.5396159101366573, 0.0, 4096, 0.0001, 0.04579536114299372, 0.7899034852113153, 0.1]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 70 for parameters [2225, 528, 60, 0.2711423932810071, 0.0007434869366203891, 1499, 0.01, 0.03341151728848744, 0.8769465382342522, 0.1]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 71 for parameters [2016, 609, 94, 0.3809339854155273, 0.0017373909147004344, 1772, 0.1, 0.022532933820033196, 0.7155531468944313, 0.1]\n",
      "Validation Score: 2.9308760622315773 RMSE 0.25013235075416085 R2 Score 787.9999518217819 S score at round 72 for parameters [1812, 329, 48, 0.2964703577813641, 0.004466578247981475, 1585, 0.001, 0.0608213992514679, 0.291629096310983, 0.1]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 73 for parameters [4096, 463, 71, 0.4684002911491676, 0.0005696245596345461, 4096, 0.01, 0.020925133028598636, 0.12536233449921946, 0.10846678360218644]\n",
      "Validation Score: 2.8549747076362477 RMSE 0.2884683214814867 R2 Score 789.2182240796592 S score at round 74 for parameters [1408, 260, 76, 0.1645154765149332, 0.0, 3260, 0.0001, 0.0, 0.7200816732976217, 0.1]\n",
      "At iteration 14 the best S score is 785.5174018310078\n",
      "[3125, 459, 80, 0.5396159101366573, 0.0, 4096, 0.0001, 0.04579536114299372, 0.7899034852113153, 0.1]\n",
      "Validation Score: 2.8990514638530867 RMSE 0.2663286501969945 R2 Score 785.8162639513179 S score at round 75 for parameters [4002, 254, 59, 0.43385139091381253, 0.0012445417297602655, 2700, 0.0001, 0.051214542958371224, 0.10768207521602813, 0.1728248839130952]\n",
      "Validation Score: 2.929101231198841 RMSE 0.25104026045589223 R2 Score 792.373234467984 S score at round 76 for parameters [1798, 163, 52, 0.37384549511561804, 0.0, 4096, 0.001, 0.027548644970749374, 0.6832910681807436, 0.1]\n",
      "Validation Score: 3.2558323528209328 RMSE 0.07463348805982706 R2 Score 824.2518044487097 S score at round 77 for parameters [1, 326, 94, 0.35677676847137524, 0.0016640946617209468, 4096, 1e-05, 0.07050698722606008, 0.34333008370222445, 0.1]\n",
      "Validation Score: 2.9296282930684376 RMSE 0.2507707008846358 R2 Score 793.3006172572419 S score at round 78 for parameters [1585, 741, 60, 0.3095487112260393, 0.0015510292328429058, 3708, 0.001, 0.0, 0.08705348620015961, 0.1495068917112104]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 79 for parameters [2687, 199, 93, 0.5632140022767751, 0.0, 4096, 0.01, 0.030428842755021696, 0.769425350051791, 0.11564187015137234]\n",
      "At iteration 15 the best S score is 785.5174018310078\n",
      "[3125, 459, 80, 0.5396159101366573, 0.0, 4096, 0.0001, 0.04579536114299372, 0.7899034852113153, 0.1]\n",
      "Validation Score: 2.960837421093368 RMSE 0.23472269860911255 R2 Score 788.1751475867082 S score at round 80 for parameters [840, 441, 25, 0.898636094794128, 0.0, 2832, 1e-06, 0.07058747325610658, 0.8155999375477301, 0.1]\n",
      "Validation Score: 2.9459080991738538 RMSE 0.24242070120816672 R2 Score 790.7694911255321 S score at round 81 for parameters [3560, 205, 129, 0.17415607023813712, 7.874415422992313e-05, 4096, 0.001, 0.008363673944139173, 0.8171321500502662, 0.1]\n",
      "Validation Score: 2.9104923535080203 RMSE 0.2605264656430317 R2 Score 786.1058199724854 S score at round 82 for parameters [3572, 598, 79, 0.6180292511514882, 0.0, 4096, 0.001, 0.0656336735903508, 0.4076152912486084, 0.1]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 83 for parameters [2750, 642, 89, 0.44004388273056205, 0.0006875965294353046, 4096, 0.1, 0.041134802617000914, 0.999, 0.1]\n",
      "Validation Score: 2.949300180027314 RMSE 0.24067505970453007 R2 Score 795.3164606394332 S score at round 84 for parameters [3161, 420, 23, 0.1783334054441014, 0.00028566046544662615, 4096, 0.001, 0.04188335648046591, 0.45991191172307977, 0.1]\n",
      "At iteration 16 the best S score is 785.5174018310078\n",
      "[3125, 459, 80, 0.5396159101366573, 0.0, 4096, 0.0001, 0.04579536114299372, 0.7899034852113153, 0.1]\n",
      "Validation Score: 2.9164529330091717 RMSE 0.2574945358884868 R2 Score 788.8516407979237 S score at round 85 for parameters [4096, 283, 86, 0.6807943483634129, 0.00015187687893528676, 3958, 0.0001, 0.056300471332892975, 0.7903892221781748, 0.16460591580594575]\n",
      "Validation Score: 2.866826673812979 RMSE 0.2825484416410041 R2 Score 790.7829354901194 S score at round 86 for parameters [3350, 423, 66, 0.5303023949858812, 0.0001935550947100845, 3543, 0.0001, 0.04084237896257938, 0.5929913940643741, 0.12617760428157965]\n",
      "Validation Score: 2.8578740227676884 RMSE 0.28702242281653945 R2 Score 788.8245899840496 S score at round 87 for parameters [4096, 397, 55, 0.5800607432450391, 8.205845998753384e-05, 2974, 0.0001, 0.056652371646452836, 0.6045430984365712, 0.10104653424257908]\n",
      "Validation Score: 2.9349416431309163 RMSE 0.24805054176518115 R2 Score 795.432087444122 S score at round 88 for parameters [4096, 521, 21, 0.4541151522321685, 0.00017237871438483964, 2154, 1e-05, 0.039313718494943715, 0.5401375945312694, 0.1]\n",
      "Validation Score: 2.848401286944621 RMSE 0.29174107381278 R2 Score 788.2127270519247 S score at round 89 for parameters [3624, 222, 28, 0.4669927491269058, 0.00016267560607455297, 3567, 0.0001, 0.04221228583728396, 0.7142808699914873, 0.1]\n",
      "At iteration 17 the best S score is 785.5174018310078\n",
      "[3125, 459, 80, 0.5396159101366573, 0.0, 4096, 0.0001, 0.04579536114299372, 0.7899034852113153, 0.1]\n",
      "Validation Score: 2.921400308591211 RMSE 0.25497327513073476 R2 Score 790.6891565835308 S score at round 90 for parameters [3830, 358, 65, 0.632445382018719, 5.1754951621143214e-05, 2435, 0.001, 0.04310472170011008, 0.5027636665504419, 0.1]\n",
      "Validation Score: 2.879369258740627 RMSE 0.27625689832798683 R2 Score 790.4315861096018 S score at round 91 for parameters [3121, 307, 78, 0.6501180206770343, 0.00010557506283621088, 3705, 0.0001, 0.05913294871835529, 0.557558291429789, 0.1]\n",
      "Validation Score: 2.894253860482506 RMSE 0.26875492768491116 R2 Score 794.8173591670405 S score at round 92 for parameters [2038, 290, 97, 0.6457239523604456, 0.0, 3925, 0.0001, 0.05309375370411795, 0.999, 0.1]\n",
      "Validation Score: 2.9405985384608955 RMSE 0.24514908800504887 R2 Score 787.7795688645882 S score at round 93 for parameters [3763, 312, 78, 0.7949623458168071, 0.0002654403601360448, 3681, 0.0001, 0.06341784116476591, 0.411576166692753, 0.12154780080832543]\n",
      "Validation Score: 2.921940165670437 RMSE 0.2546978968381761 R2 Score 799.6111802071642 S score at round 94 for parameters [2707, 393, 83, 0.4456188164579853, 0.00010687932169266333, 3886, 0.001, 0.050032730341722766, 0.999, 0.1]\n",
      "At iteration 18 the best S score is 785.5174018310078\n",
      "[3125, 459, 80, 0.5396159101366573, 0.0, 4096, 0.0001, 0.04579536114299372, 0.7899034852113153, 0.1]\n",
      "Validation Score: 2.8918461688640082 RMSE 0.2699710479019348 R2 Score 786.9181713797918 S score at round 95 for parameters [3657, 305, 73, 0.4170190118531054, 3.593109955396681e-05, 2398, 0.0001, 0.02645968946314084, 0.13907273317318963, 0.1]\n",
      "Validation Score: 2.9275138915537666 RMSE 0.2518517935927592 R2 Score 790.2090963249427 S score at round 96 for parameters [2187, 291, 57, 0.2591151101137395, 0.0002230883667236754, 2898, 0.001, 0.03932187749960365, 0.5200889688904622, 0.1]\n",
      "Validation Score: 2.9032883637382896 RMSE 0.26418259408664635 R2 Score 787.3343912135084 S score at round 97 for parameters [2500, 243, 58, 0.3312554983264292, 0.00012351111973265205, 2412, 0.001, 0.031199859058283375, 0.3716503458672339, 0.1]\n",
      "Validation Score: 2.9462105310765963 RMSE 0.24226514448214276 R2 Score 791.9991126663338 S score at round 98 for parameters [2036, 351, 47, 0.38709851516103416, 0.00029685883391213536, 2762, 0.001, 0.051519933552522885, 0.4686002877188876, 0.1]\n",
      "Validation Score: 2.925421558550983 RMSE 0.25292083431741796 R2 Score 790.9090322764545 S score at round 99 for parameters [2859, 211, 52, 0.4815089214327357, 0.0005795437975861524, 4096, 0.001, 0.044443927615202515, 0.561895426257826, 0.1]\n",
      "At iteration 19 the best S score is 785.5174018310078\n",
      "[3125, 459, 80, 0.5396159101366573, 0.0, 4096, 0.0001, 0.04579536114299372, 0.7899034852113153, 0.1]\n",
      "Validation Score: 2.931699261577248 RMSE 0.24971105880272348 R2 Score 793.0116825686251 S score at round 100 for parameters [2583, 396, 69, 0.495349522536738, 0.00025084387250968115, 4096, 0.001, 0.04543724720485068, 0.49105350385527713, 0.10796817396875481]\n",
      "Validation Score: 2.928125556945413 RMSE 0.2515391295446382 R2 Score 789.2504567232667 S score at round 101 for parameters [3759, 439, 60, 0.4618297531895389, 0.00010291961492374136, 2003, 0.001, 0.02778489929070469, 0.4286629290015668, 0.10620233351462002]\n",
      "Validation Score: 2.9257394000748502 RMSE 0.25275848801954925 R2 Score 791.893464721618 S score at round 102 for parameters [2961, 324, 58, 0.6037675270839613, 0.00022657019522206472, 3837, 0.001, 0.03689401777093944, 0.5604881929014719, 0.1]\n",
      "Validation Score: 2.9309215330678615 RMSE 0.25010908305338575 R2 Score 790.4604612527694 S score at round 103 for parameters [3357, 286, 69, 0.3908663346303603, 0.00010291803667034626, 3368, 0.001, 0.0477216215763111, 0.3946321260237484, 0.1]\n",
      "Validation Score: 2.9508078683103007 RMSE 0.23989852434760794 R2 Score 792.0989359114742 S score at round 104 for parameters [3101, 416, 67, 0.425658985337667, 9.215547133877594e-05, 4096, 0.001, 0.05412201447449548, 0.5526689913592607, 0.10631293612234684]\n",
      "At iteration 20 the best S score is 785.5174018310078\n",
      "[3125, 459, 80, 0.5396159101366573, 0.0, 4096, 0.0001, 0.04579536114299372, 0.7899034852113153, 0.1]\n",
      "Validation Score: 2.970433142561745 RMSE 0.2297543154749857 R2 Score 802.6159577097943 S score at round 105 for parameters [3589, 541, 74, 0.5854318734572164, 9.876150798871426e-05, 3658, 0.001, 0.04822898653546961, 0.8771909672926979, 0.10516982975585976]\n",
      "Validation Score: 2.8753381180163546 RMSE 0.2782819724048662 R2 Score 790.1068351468177 S score at round 106 for parameters [3308, 396, 76, 0.649702769716587, 8.528762835863867e-05, 4096, 0.0001, 0.03202482922064944, 0.5661808025507262, 0.10433981047588628]\n",
      "Validation Score: 2.847395913846611 RMSE 0.2922409604044388 R2 Score 786.9626845486654 S score at round 107 for parameters [3019, 420, 66, 0.5492164378340731, 0.00013369625134990686, 4096, 0.0001, 0.03606187195075419, 0.6849184849356569, 0.1]\n",
      "Validation Score: 2.9684671693579503 RMSE 0.23077354815358808 R2 Score 799.4531916465431 S score at round 108 for parameters [2646, 374, 76, 0.5447284268804373, 0.00010197302724375418, 4095, 0.001, 0.04672130220891921, 0.7668518886669936, 0.1]\n",
      "Validation Score: 2.8649754335352213 RMSE 0.28347472463031054 R2 Score 788.1342878399204 S score at round 109 for parameters [2980, 401, 82, 0.6377806671799188, 3.49772815979185e-05, 4096, 0.0001, 0.047291340543026535, 0.553616989499506, 0.10515985297911254]\n",
      "At iteration 21 the best S score is 785.5174018310078\n",
      "[3125, 459, 80, 0.5396159101366573, 0.0, 4096, 0.0001, 0.04579536114299372, 0.7899034852113153, 0.1]\n",
      "Validation Score: 2.942451938444278 RMSE 0.24419725351080612 R2 Score 791.9830397253457 S score at round 110 for parameters [2544, 316, 58, 0.44287194364876376, 0.00029826925894849366, 2739, 0.001, 0.04112554269633352, 0.43618828054952175, 0.10498870145358888]\n",
      "Validation Score: 2.9305883338310648 RMSE 0.25027957474049256 R2 Score 790.6721928505484 S score at round 111 for parameters [2458, 239, 56, 0.32663463392813247, 0.0003714648654271116, 2667, 0.001, 0.03687685011104158, 0.4762340396327628, 0.1]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 112 for parameters [2431, 263, 58, 0.3168883945063946, 0.00028797788955058936, 2650, 0.01, 0.0406411933947812, 0.34496835813143356, 0.1]\n",
      "Validation Score: 2.9430991406763694 RMSE 0.24386473421691524 R2 Score 793.3402901720625 S score at round 113 for parameters [2543, 320, 57, 0.3614183748651034, 0.00016849035075940355, 2779, 0.001, 0.035864779264905285, 0.36639774181531765, 0.1]\n",
      "Validation Score: 2.9426370212547397 RMSE 0.2441021692077281 R2 Score 796.2525047254248 S score at round 114 for parameters [2642, 301, 57, 0.38310205394467767, 0.00023071986800352198, 2969, 0.001, 0.03688482110164393, 0.4742918532853857, 0.1]\n",
      "At iteration 22 the best S score is 785.5174018310078\n",
      "[3125, 459, 80, 0.5396159101366573, 0.0, 4096, 0.0001, 0.04579536114299372, 0.7899034852113153, 0.1]\n",
      "Validation Score: 2.924983922134796 RMSE 0.253144340288586 R2 Score 793.4848560196813 S score at round 115 for parameters [2556, 400, 64, 0.45503392046992375, 0.0001783379074127378, 3223, 0.001, 0.03620613898524901, 0.5560812949384965, 0.1]\n",
      "Validation Score: 2.9525914311237775 RMSE 0.23897938728561474 R2 Score 794.6090401025492 S score at round 116 for parameters [2874, 393, 60, 0.40556565287131263, 0.00019340767045516395, 2968, 0.001, 0.03837772929819966, 0.5886098828003902, 0.10128529346753447]\n",
      "Validation Score: 5.435810104856772 RMSE -1.5793974329220561 R2 Score 913.251694683537 S score at round 117 for parameters [2705, 309, 68, 0.4265262366725121, 0.00024218120473528954, 3216, 0.001, 0.04034182354344756, 0.5298817904101605, 0.1]\n",
      "Validation Score: 2.9223976821705935 RMSE 0.254464480213357 R2 Score 790.6417353105154 S score at round 118 for parameters [2872, 393, 61, 0.4377981093358809, 0.00023383269643215842, 3129, 0.001, 0.03889695106749868, 0.5440284620053939, 0.1]\n",
      "Validation Score: 2.9074980420006646 RMSE 0.26204722217074017 R2 Score 785.31867266152 S score at round 119 for parameters [2737, 360, 78, 0.4358910532296705, 0.0001837537352680288, 3495, 0.001, 0.035821945808348674, 0.4489307538261566, 0.1066162771521442]\n",
      "At iteration 23 the best S score is 785.31867266152\n",
      "[2737, 360, 78, 0.4358910532296705, 0.0001837537352680288, 3495, 0.001, 0.035821945808348674, 0.4489307538261566, 0.1066162771521442]\n",
      "Validation Score: 2.9381689917789475 RMSE 0.2463959007842783 R2 Score 793.9740839272064 S score at round 120 for parameters [2618, 317, 82, 0.48155792203129577, 0.00017836377593143175, 3125, 0.001, 0.03717159635439269, 0.4571807875569375, 0.1]\n",
      "Validation Score: 2.9272005632236433 RMSE 0.25201193184811665 R2 Score 789.462781278409 S score at round 121 for parameters [2742, 308, 71, 0.3898537477055716, 0.0001945177192740895, 3738, 0.001, 0.03970648563626107, 0.3707623458581126, 0.10069993691797344]\n",
      "Validation Score: 2.9330977949572734 RMSE 0.24899505466006744 R2 Score 793.2780854302559 S score at round 122 for parameters [2304, 344, 69, 0.40749967693992417, 0.00015790242348224379, 3527, 0.001, 0.03756714335060348, 0.4416229619180357, 0.1]\n",
      "Validation Score: 2.92382629388348 RMSE 0.2537353931939059 R2 Score 786.6867285921547 S score at round 123 for parameters [2628, 329, 65, 0.3631882622664613, 0.00020251733919620285, 3370, 0.001, 0.03891917204725944, 0.5175738636084692, 0.10115752572912426]\n",
      "Validation Score: 2.9435286267113914 RMSE 0.243644032693083 R2 Score 791.7259272970964 S score at round 124 for parameters [2655, 323, 71, 0.38589300647248637, 0.00018795964079085326, 3566, 0.001, 0.036901672708264124, 0.4393133171173778, 0.1]\n",
      "At iteration 24 the best S score is 785.31867266152\n",
      "[2737, 360, 78, 0.4358910532296705, 0.0001837537352680288, 3495, 0.001, 0.035821945808348674, 0.4489307538261566, 0.1066162771521442]\n",
      "Validation Score: 2.9130913663370084 RMSE 0.25920520512826517 R2 Score 788.9088272371146 S score at round 125 for parameters [2627, 308, 78, 0.3791475554613562, 0.00018930348564869, 3439, 0.001, 0.035327572042749715, 0.4473429857637867, 0.1]\n",
      "Validation Score: 2.9299994519205286 RMSE 0.25058084696859817 R2 Score 793.4819445559189 S score at round 126 for parameters [2743, 358, 77, 0.47328662027176327, 0.0001962548734149572, 3269, 0.001, 0.03563234427173062, 0.4908064254640395, 0.10490099420692854]\n",
      "Validation Score: 2.9406384360473914 RMSE 0.2451286044650699 R2 Score 793.8852265667342 S score at round 127 for parameters [2744, 370, 73, 0.4117875460434535, 0.00015898973682389466, 3510, 0.001, 0.034890747082578465, 0.4520216931780549, 0.10341650881129595]\n",
      "Validation Score: 2.935344650972426 RMSE 0.24784402158807217 R2 Score 793.5291994330205 S score at round 128 for parameters [2623, 399, 78, 0.45693298058338516, 0.00018029112402384852, 3442, 0.001, 0.036883117821752895, 0.5338651670563921, 0.10801080581432951]\n",
      "Validation Score: 2.933218396131433 RMSE 0.2489332947416597 R2 Score 792.1648710583974 S score at round 129 for parameters [2727, 324, 85, 0.3909772555329739, 0.00018178397317678645, 3570, 0.001, 0.0371272542001837, 0.4522137587165167, 0.11020188715174326]\n",
      "At iteration 25 the best S score is 785.31867266152\n",
      "[2737, 360, 78, 0.4358910532296705, 0.0001837537352680288, 3495, 0.001, 0.035821945808348674, 0.4489307538261566, 0.1066162771521442]\n",
      "Validation Score: 2.9060605538466864 RMSE 0.26277674021532194 R2 Score 787.5114613416513 S score at round 130 for parameters [2607, 354, 78, 0.45865684750802366, 0.00017759181053528863, 3486, 0.001, 0.03607926819040116, 0.44812322165282764, 0.11306177896428293]\n",
      "Validation Score: 2.9332214751666865 RMSE 0.24893171793300495 R2 Score 792.5784547243278 S score at round 131 for parameters [2738, 359, 78, 0.4554824692573486, 0.00016907355847473488, 3613, 0.001, 0.03559790033536337, 0.452173837499522, 0.10739239662255126]\n",
      "Validation Score: 2.932848398407769 RMSE 0.24912276269593736 R2 Score 793.6424468132318 S score at round 132 for parameters [2733, 365, 82, 0.4564607569292801, 0.00017645995033513346, 3512, 0.001, 0.03686259013842943, 0.4493797851999462, 0.10733507234773543]\n",
      "Validation Score: 2.9313169335759293 RMSE 0.249906739014765 R2 Score 790.8399158035273 S score at round 133 for parameters [2677, 357, 78, 0.44579034236601, 0.00018223806030484997, 3522, 0.001, 0.03553868779581152, 0.34980152610586124, 0.10618979375426042]\n",
      "Validation Score: 2.9258437346738466 RMSE 0.25270519240913136 R2 Score 792.3951467801974 S score at round 134 for parameters [2742, 368, 74, 0.4310661702316323, 0.00018408294748011367, 3492, 0.001, 0.036407367348138056, 0.4478603862505405, 0.10846455006277567]\n",
      "At iteration 26 the best S score is 785.31867266152\n",
      "[2737, 360, 78, 0.4358910532296705, 0.0001837537352680288, 3495, 0.001, 0.035821945808348674, 0.4489307538261566, 0.1066162771521442]\n",
      "Validation Score: 2.932971373282987 RMSE 0.24905979253320543 R2 Score 786.0326939028245 S score at round 135 for parameters [2681, 357, 78, 0.4106490550513099, 0.00017714399729083089, 3491, 0.001, 0.0359081570527811, 0.44869166787246034, 0.11295684589030293]\n",
      "Validation Score: 2.9299081841390513 RMSE 0.2506275341843057 R2 Score 790.1259507111091 S score at round 136 for parameters [2736, 360, 78, 0.44877118439923835, 0.00017666532653982413, 3379, 0.001, 0.03572641942598404, 0.4473158510896302, 0.10652041422831822]\n",
      "Validation Score: 2.9247616024953915 RMSE 0.2532578686875354 R2 Score 789.7202754594869 S score at round 137 for parameters [2736, 355, 78, 0.43873658611145144, 0.000178471759971378, 3503, 0.001, 0.03578857101745204, 0.4491779114727881, 0.10601366451792864]\n",
      "Validation Score: 2.9210276628733554 RMSE 0.2551633300923727 R2 Score 788.4580886077297 S score at round 138 for parameters [2671, 359, 78, 0.4400217738381087, 0.00018476493684350983, 3468, 0.001, 0.03606499820741457, 0.43146246172096714, 0.10677708231237629]\n",
      "Validation Score: 2.9283045538134287 RMSE 0.25144761963913076 R2 Score 792.4884239385275 S score at round 139 for parameters [2731, 359, 76, 0.4340811891001829, 0.00018389903278578427, 3493, 0.001, 0.035865239813382015, 0.44948268946010755, 0.10753134447296449]\n",
      "At iteration 27 the best S score is 785.31867266152\n",
      "[2737, 360, 78, 0.4358910532296705, 0.0001837537352680288, 3495, 0.001, 0.035821945808348674, 0.4489307538261566, 0.1066162771521442]\n",
      "Validation Score: 2.9304937960223794 RMSE 0.25032794440204054 R2 Score 792.0738340025977 S score at round 140 for parameters [2720, 361, 78, 0.4368797869193101, 0.00018738180927899324, 3492, 0.001, 0.03583533316650218, 0.4489688442259375, 0.10532976714226355]\n",
      "Validation Score: 2.9303458539583453 RMSE 0.2504036348756954 R2 Score 788.1160896541373 S score at round 141 for parameters [2737, 360, 78, 0.4396158113764162, 0.0001870377178797408, 3537, 0.001, 0.035814449314744486, 0.45061775061790554, 0.10664348137633804]\n",
      "Validation Score: 2.9225532246861663 RMSE 0.2543851169173119 R2 Score 789.887962152311 S score at round 142 for parameters [2736, 358, 78, 0.43644778326716055, 0.00018800438302011936, 3491, 0.001, 0.03583632762093507, 0.4491343680604466, 0.10659526195362752]\n",
      "Validation Score: 2.9242219047974998 RMSE 0.25353343154042174 R2 Score 787.5334296022822 S score at round 143 for parameters [2724, 360, 78, 0.4349974676820783, 0.00018417996679913267, 3519, 0.001, 0.03589361080395481, 0.44167175438196093, 0.10654665112919219]\n",
      "Validation Score: 2.9349032821376984 RMSE 0.2480701982647393 R2 Score 793.4872727542387 S score at round 144 for parameters [2738, 361, 78, 0.4375629254694193, 0.0001837011610211625, 3494, 0.001, 0.0358632054182839, 0.44913849136841677, 0.1069450458177536]\n",
      "At iteration 28 the best S score is 785.31867266152\n",
      "[2737, 360, 78, 0.4358910532296705, 0.0001837537352680288, 3495, 0.001, 0.035821945808348674, 0.4489307538261566, 0.1066162771521442]\n",
      "Validation Score: 2.9323802670844965 RMSE 0.24936244852596867 R2 Score 789.7806443017165 S score at round 145 for parameters [2754, 360, 78, 0.4354710179561808, 0.00018230814748377002, 3494, 0.001, 0.03581264699019238, 0.4489150998230014, 0.10625013469841085]\n",
      "Validation Score: 2.929022116367916 RMSE 0.25108071861576187 R2 Score 791.0310513765784 S score at round 146 for parameters [2737, 360, 78, 0.43629821086590276, 0.00018639778265542472, 3504, 0.001, 0.035815060125630974, 0.4496993644263341, 0.10660611356245858]\n",
      "Validation Score: 2.924504690631604 RMSE 0.25338905099423514 R2 Score 791.111472692725 S score at round 147 for parameters [2736, 360, 78, 0.43588818659936385, 0.0001867432182948155, 3491, 0.001, 0.035808165661067565, 0.44880026496981007, 0.10660940774581042]\n",
      "Validation Score: 2.931498397913105 RMSE 0.249813866498663 R2 Score 790.3496950687866 S score at round 148 for parameters [2731, 360, 78, 0.43625609159045303, 0.00018411193821113344, 3486, 0.001, 0.03588988992477763, 0.4504109636424844, 0.1066050719934821]\n",
      "Validation Score: 2.9358871190361255 RMSE 0.24756599065953033 R2 Score 788.8411093112131 S score at round 149 for parameters [2737, 361, 78, 0.43644701521403, 0.00018375587972245118, 3494, 0.001, 0.03582053652686673, 0.44900231514842404, 0.10629391079189009]\n",
      "At iteration 29 the best S score is 785.31867266152\n",
      "[2737, 360, 78, 0.4358910532296705, 0.0001837537352680288, 3495, 0.001, 0.035821945808348674, 0.4489307538261566, 0.1066162771521442]\n"
     ]
    }
   ],
   "source": [
    "result = GWO(findFitnessScore, paramsLowerBoundList, paramsUpperBoundList, numParams, 5, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05fa76c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: [2737, 360, 78, 0.4358910532296705, 0.0001837537352680288, 3495, 0.001, 0.035821945808348674, 0.4489307538261566, 0.1066162771521442] with score 785.31867266152\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best hyperparameters: {result.bestIndividual} with score {result.best}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81835767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(result.convergence)\n",
    "plt.ylabel('S Score')\n",
    "plt.xlabel('Iterations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87af2e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
